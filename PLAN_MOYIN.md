# AI 影视制作平台功能升级规划 (借鉴 Moyin Creator)

基于对开源项目 [Moyin Creator](https://github.com/MemeCalculate/moyin-creator) 的调研，结合我们现有平台的特点，梳理出以下可借鉴的功能模块和升级路线。我们的目标是打造一个从**剧本到成片**的全流程、批量化 AI 影视生产工具。

## 🎯 核心借鉴点概览

| 板块 | Moyin Creator 特性 | 我们平台现状 | 借鉴/升级方向 | 优先级 |
| :--- | :--- | :--- | :--- | :--- |
| **剧本解析** | 智能拆解剧本为场景、分镜、对白 | 仅简单的剧本编辑器 | **引入智能剧本解析引擎**，自动提取实体 | P0 |
| **角色系统** | 6层身份锚点、角色圣经 (Character Bible) | 基础的角色卡片 (Asset Library) | **建立“角色一致性系统”**，支持多层级特征锁定 | P0 |
| **场景生成** | 多视角联合图生成 | 基础的场景卡片 | **场景多视角扩展**，与角色系统解耦但可组合 | P1 |
| **分镜系统** | 电影级参数（景别、机位）、自动排版 | 简单的关键帧生成 | **引入专业分镜参数控制**，支持视觉风格切换 | P1 |
| **视频生成** | 多镜头合并叙事、首帧图网格拼接 | 单镜头生成 | **多镜头连贯生成 (Seedance 2.0 模式)** | P2 |
| **工作流** | 环环相扣，自动流入下一步 | 步骤较为独立 | **打造全自动流水线** (Pipeline) | P2 |

---

## 🚀 详细实施路线图

### 第一阶段：剧本与角色核心 (Foundation)

#### 1. 智能剧本解析引擎 (Script Parser)
*   **功能描述**：用户输入一段文本剧本，AI 自动将其拆解为结构化数据。
*   **实现逻辑**：
    *   **输入**：纯文本剧本。
    *   **处理**：使用 LLM (如 Doubao/DeepSeek) 分析文本。
    *   **输出**：结构化 JSON，包含：
        *   `Scene` (场景)：地点、时间、环境描述。
        *   `Character` (角色)：出场人物、情绪、动作。
        *   `Dialogue` (对白)：台词内容。
        *   `Shot` (镜头)：建议的景别 (远/中/近)、运镜方式。
*   **UI 交互**：左侧输入剧本，右侧实时生成分镜列表卡片。

#### 2. 角色一致性系统升级 (Character Consistency)
*   **功能描述**：增强现有的 Asset Library，使其不仅是图片库，而是生图的“约束源”。
*   **借鉴点**：
    *   **角色圣经 (Character Bible)**：允许用户定义角色的文字设定集（外貌、性格、典型服饰），作为全局 Prompt 前缀。
    *   **身份锚点**：在生成分镜时，强制通过 `ReferenceNet` 或 `IP-Adapter` 传入角色参考图，确保人脸和服装一致性。
    *   **多状态管理**：一个角色可以有多个“状态”（如：便服、战损、礼服），不仅仅是单一形象。

---

### 第二阶段：专业分镜与场景 (Visual Production)

#### 3. 场景与分镜系统 (Storyboard System)
*   **功能描述**：将解析出的结构化数据转换为视觉分镜。
*   **借鉴点**：
    *   **参数化控制**：在分镜编辑卡片中，增加下拉菜单选择：
        *   **景别**：特写 (Close-up)、中景 (Medium)、全景 (Wide)、大远景 (Extreme Wide)。
        *   **视角**：平视 (Eye-level)、仰视 (Low angle)、俯视 (High angle)。
        *   **光影**：自然光、赛博朋克、电影布光。
    *   **场景一致性**：支持“场景锁定”。即生成第一张场景图后，后续同场景的分镜均以该图为 `Image-to-Image` 或 `ControlNet` 参考，保持背景连贯。

#### 4. 视觉风格控制器 (Style Controller)
*   **功能描述**：全局控制整部影片的画风。
*   **实现**：提供预设风格库（2D 动漫、3D 迪士尼、写实电影、水墨风等），一键替换所有分镜的 Prompt 风格后缀。

---

### 第三阶段：视频生成与自动化 (Motion & Pipeline)

#### 5. 视频生成与拼接 (Video Generation)
*   **功能描述**：将静态分镜图转为动态视频。
*   **借鉴点**：
    *   **多模态引用**：支持引用上一镜头的尾帧作为当前镜头的首帧（首尾帧连贯）。
    *   **Seedance 模式**：尝试实现类似 Seedance 的逻辑，一次性生成多段连续动作，或者通过 N×N 网格图生成策略来保持连贯性。
    *   **时长控制**：允许为每个镜头设定 2s/4s/5s 时长。

#### 6. 批量化生产队列 (Batch Pipeline)
*   **功能描述**：解决“等待焦虑”，实现后台批量处理。
*   **实现**：
    *   **任务队列**：用户点击“生成全片”后，系统将所有分镜任务加入队列。
    *   **状态监控**：提供一个 Dashboard 查看所有任务的进度（排队中 -> 生成中 -> 完成/失败）。
    *   **自动重试**：API 调用失败时自动重试 3 次。

---

## 🛠 技术架构调整建议

为了支撑上述功能，我们需要对现有架构进行微调：

1.  **数据库设计 (IndexedDB/Postgres)**：
    *   新增 `Script` 表：存储原始剧本和解析后的结构。
    *   新增 `Storyboard` 表：存储分镜列表，关联 `Script` 和 `Asset`。
    *   `Asset` 表升级：增加 `tags` (身份锚点)、`variants` (多状态) 字段。

2.  **AI 服务层 (Server Actions)**：
    *   `aiClient` 需扩展支持 LLM 文本分析接口（用于剧本解析）。
    *   增加 `PromptBuilder` 工具类，负责将角色、场景、分镜参数、风格组合成最终的绘画 Prompt。

3.  **前端交互**：
    *   引入 `React Flow` 或类似的节点编辑器，可视化展示“剧本 -> 分镜 -> 视频”的流转关系（可选，后期进阶）。
    *   增强 `Timeline` 组件，支持视频片段的预览和排序。

---

## 📅 下一步行动 (Action Plan)

1.  **本周任务**：完成 **[第一阶段：剧本解析引擎]** 的开发。
    *   设计剧本解析的 Prompt。
    *   开发剧本输入与拆解 UI。
    *   实现“文本 -> 结构化分镜”的数据流转。

2.  **后续**：基于拆解出的分镜，结合现有的 `AssetLibrary` 进行角色绑定。
