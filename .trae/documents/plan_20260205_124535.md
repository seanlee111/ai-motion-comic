为了满足您集成多平台（即梦、可灵等）并统一管理配置的需求，我设计了一套**可扩展的 AI Provider 架构**。

### 核心改进
1.  **去中心化 API Key**：不再硬编码 `FAL_KEY`。我们将建立一个统一的“模型注册表”，您可以为每个模型单独指定环境变量（如 `KLING_KEY`, `JIMENG_KEY`）。
2.  **Provider 适配器模式**：我将重构后端，为 Fal、可灵 (Kling)、即梦 (Jimeng) 分别建立独立的“驱动程序”。
    *   **Fal**: 保持现有功能。
    *   **Kling & Jimeng**: 我将为您搭建好标准的 API 调用骨架（包含认证头、请求体结构），由于官方 API 地址可能变动，您只需在代码注释处填入最新的 Endpoint URL 即可使用。
3.  **统一配置中心**: 新建 `lib/ai-models.ts`，在这里您可以一目了然地管理所有可用模型、对应的 API Key 变量名以及显示名称。

### 实施计划

#### Step 1: 建立模型注册表 (`lib/ai-models.ts`)
我们将定义一个配置清单，例如：
```typescript
export const AI_MODELS = [
  { id: 'fal-flux', provider: 'FAL', name: 'Flux Pro', envKey: 'FAL_KEY' },
  { id: 'kling-v1', provider: 'KLING', name: 'Kling 1.0', envKey: 'KLING_KEY' },
  { id: 'jimeng-v1', provider: 'JIMENG', name: 'Jimeng', envKey: 'JIMENG_KEY' }
]
```

#### Step 2: 重构后端逻辑 (`app/api/generate/`)
拆分单一的 `route.ts`，创建 `providers/` 目录：
*   `fal.ts`: 封装现有的 Fal 调用逻辑。
*   `kling.ts`: **新增**。实现可灵的异步任务提交与轮询逻辑（预置代码桩）。
*   `jimeng.ts`: **新增**。实现即梦的调用逻辑（预置代码桩）。
*   `route.ts`: 变成一个“路由器”，根据前端传来的 `modelId` 自动分发给对应的 Provider。

#### Step 3: 前端动态适配
更新 `StoryboardFrame`，使其不再写死模型列表，而是从配置中心读取。这样您以后添加新模型，只需改配置文件，前端下拉菜单会自动更新。

### 您的后续工作
由于我无法访问您私有的企业级 API 权限，代码部署后，您需要：
1.  在 Vercel 环境变量中添加 `KLING_KEY` 等。
2.  如果可灵/即梦的 API 地址有变，在 `lib/ai-providers/` 对应的文件中微调 URL。

请确认是否执行此重构计划？